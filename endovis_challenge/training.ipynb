{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XV4kwK6tphAb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607442167302,"user_tz":-60,"elapsed":1431,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"fa391e73-2bf4-4198-fbe8-ad54078e5090"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G-D70lClSEnQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607425955829,"user_tz":-60,"elapsed":21657,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"3e203bc0-98c7-4162-ebad-ecb75037a77d"},"source":["%cd /content/drive/Shared\\ drives/TFM_Clara/6_robot-surgery-segmentation-master"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/TFM_Clara/6_robot-surgery-segmentation-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fWkOd7oMQbaW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607425964452,"user_tz":-60,"elapsed":30267,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"8a444771-75c4-41a4-9e0d-7ef9a52be372"},"source":["!pip3 install albumentations"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n","Collecting imgaug<0.2.7,>=0.2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n","\u001b[K     |████████████████████████████████| 634kB 9.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654021 sha256=89dfa2a9e5ad4f1c2bf39d58583bf049e4d07c31725267dd4a8a77716b6a23d0\n","  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"odjBERuqQbbP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607425967275,"user_tz":-60,"elapsed":33082,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"8f8c381b-1c72-4f78-c8eb-2889dde46e93"},"source":["!pip install torchvision"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n","Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef9q346ALk0H","executionInfo":{"status":"ok","timestamp":1607426151634,"user_tz":-60,"elapsed":78318,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"db548424-2457-4ecb-c7d6-3b1a6ec5f67e"},"source":["!sh train_ft.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["linknet\n","Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","100% 83.3M/83.3M [00:02<00:00, 34.2MB/s]\n","2632\n","num train = 1579, num_val = 1053\n","Restored model, epoch 21, step 1,700\n","Epoch 21, lr 0.0001:   0% 0/1580 [00:31<?, ?it/s]\n","Ctrl+C, saving snapshot\n","done.\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mImLMtUQ8Ffh"},"source":["from torch import nn\n","from loss import LossBinary\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader\n","%matplotlib inline\n","from pylab import *\n","import cv2\n","import torch\n","from dataset_ft import load_image\n","from dataset_ft import load_mask\n","from utils import cuda\n","from generate_masks import get_model\n","from albumentations import Compose, Normalize\n","from albumentations.pytorch.functional import img_to_tensor\n","from validation import validation_binary\n","from dataset import RoboticsDataset\n","import glob\n","import matplotlib.pyplot as plt\n","from torch.utils.data.dataset import Dataset  # For custom data-sets\n","from torchvision import transforms\n","from torchsummary import summary\n","rcParams['figure.figsize'] = 10, 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbQP5b9uwCo1"},"source":["def img_transform(p=1):\n","    return Compose([\n","        Normalize(p=1)\n","    ], p=p)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgtNHqWRQbbL"},"source":["def mask_overlay(image, mask, color=(0, 255, 0)):\n","    \"\"\"\n","    Helper function to visualize mask on the top of the car\n","    \"\"\"\n","    mask = np.dstack((mask, mask, mask)) * np.array(color)\n","    mask = mask.astype(np.uint8)\n","    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)\n","    img = image.copy()\n","    ind = mask[:, :, 1] > 0    \n","    img[ind] = weighted_sum[ind]    \n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cuCNw-4Xv87U","executionInfo":{"status":"ok","timestamp":1606766557551,"user_tz":-60,"elapsed":1273,"user":{"displayName":"Clara Tomasini","photoUrl":"","userId":"02923575374060854257"}},"outputId":"d02a2d3d-2897-4521-8aaa-5e621dd00252"},"source":["root = !pwd\n","root = root[0]\n","root"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/Shareddrives/TFM_Clara/6_robot-surgery-segmentation-master'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Wv_Sz_avU-YN"},"source":["model_path = 'data/models/linknet_binary_20/model_0.pt'\n","model = get_model(model_path, model_type='LinkNet34', problem_type='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iFAhCcLBZ7X"},"source":["from train_ft import train\n","\n","jaccard_weight = 0.3\n","\n","root = !pwd\n","root = root[0]\n","batch_size = 2\n","n_epochs = 20\n","lr1 = 0.0001\n","lr2 = 0.00001\n","num_workers = 12\n","train_size = 0.6\n","train_crop_height = 1056\n","train_crop_width = 1440\n","val_crop_height = 1056\n","val_crop_width = 1440\n","fold = [\"train_data/video9_raw\",\"train_data/video6_raw\",\"train_data/video39_raw\"]\n","fold = [\"train_data/video9_raw\"]\n","heights = [1056,1056,1056]\n","widths = [1920,1920,1440]\n","for i in range(len(fold)):\n","  print(fold[i])\n","  train(model, \"linknet\", 0, \"ent\", jaccard_weight, fold[i], root, batch_size, n_epochs+50+20*i, lr1, num_workers, 1, train_size, heights[i], widths[i], heights[i], widths[i])\n","  train(model, \"linknet\", 0, \"ent\", jaccard_weight, fold[i], root, batch_size, n_epochs+60+20*i, lr2, num_workers, 1, train_size, heights[i], widths[i], heights[i], widths[i])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3aepUWpyP8X"},"source":[""],"execution_count":null,"outputs":[]}]}